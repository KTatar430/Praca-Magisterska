{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dea56c6",
   "metadata": {},
   "source": [
    "# CL na MSL z pyCLAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f4e68",
   "metadata": {},
   "source": [
    "### Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3eb26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_data_dir = os.path.join(\"data/train\")\n",
    "test_data_dir = os.path.join(\"data/test\")\n",
    "\n",
    "metadata = pd.read_csv(\"labeled_anomalies.csv\")\n",
    "msl_channels = metadata[metadata['spacecraft'] == 'MSL']['chan_id'].tolist()\n",
    "\n",
    "# Wczytanie danych treningowych\n",
    "train_data = {}\n",
    "for channel in msl_channels:\n",
    "    npy_path = os.path.join(train_data_dir, f\"{channel}.npy\")\n",
    "    if os.path.exists(npy_path):\n",
    "        arr = np.load(npy_path)\n",
    "        train_data[channel] = arr[:, 0] \n",
    "    else:\n",
    "        print(f\"Brak pliku: {npy_path}\")\n",
    "\n",
    "# Wczytanie danych testowych\n",
    "test_data = {}\n",
    "for channel in msl_channels:\n",
    "    npy_path = os.path.join(test_data_dir, f\"{channel}.npy\")\n",
    "    if os.path.exists(npy_path):\n",
    "        arr = np.load(npy_path)\n",
    "        test_data[channel] = arr[:, 0] \n",
    "    else:\n",
    "        print(f\"Brak pliku: {npy_path}\")\n",
    "\n",
    "# Normalizacja danych do 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "for channel in list(train_data.keys()):\n",
    "    train_data[channel] = scaler.fit_transform(train_data[channel].reshape(-1, 1))\n",
    "    test_data[channel] = scaler.transform(test_data[channel].reshape(-1, 1))\n",
    "\n",
    "# Tworzenie etykiet\n",
    "test_labels = {}\n",
    "for channel in msl_channels:\n",
    "    values = test_data[channel]\n",
    "    labels = np.zeros(len(values), dtype=int) \n",
    "\n",
    "    channel_meta = metadata[metadata['chan_id'] == channel]\n",
    "    if not channel_meta.empty:\n",
    "        seq_str = channel_meta.iloc[0]['anomaly_sequences']\n",
    "        if pd.notnull(seq_str) and seq_str != '[]':\n",
    "            anomaly_intervals = eval(seq_str)\n",
    "            for start, end in anomaly_intervals:\n",
    "                start_idx = max(0, start)\n",
    "                end_idx = min(len(values)-1, end)\n",
    "                labels[start_idx:end_idx+1] = 1\n",
    "\n",
    "    test_labels[channel] = labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706e71b7",
   "metadata": {},
   "source": [
    "### Funkcja tworzenia okien czasowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a49583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(data, window_size=10, step_size=1):\n",
    "    arr = np.asarray(data)\n",
    "    if arr.ndim > 1:\n",
    "        arr = arr.reshape(-1)\n",
    "    windows = []\n",
    "    for start in range(0, len(arr) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        windows.append(arr[start:end].astype(float))\n",
    "    return np.array(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "042cc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window_labels(labels, window_size=10, step_size=1):\n",
    "    window_labels = []\n",
    "    for start in range(0, len(labels) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        window_labels.append(int(labels[start:end].any()))  # jeśli choć jedna próbka jest anomalna, etykieta okna mówi o anomalii\n",
    "    return np.array(window_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772f2ef",
   "metadata": {},
   "source": [
    "### Tworzenie okien czasowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a863b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametry okna czasowego\n",
    "window_size = 30\n",
    "step_size = 10\n",
    "\n",
    "# Tworzenie okien dla wszystkich kanałów\n",
    "train_windows = {}\n",
    "test_windows = {}\n",
    "\n",
    "for channel in train_data.keys():\n",
    "    train_windows[channel] = create_windows(train_data[channel], window_size, step_size)\n",
    "    test_windows[channel] = create_windows(test_data[channel], window_size, step_size)\n",
    "    test_labels[channel] = create_window_labels(test_labels[channel], window_size, step_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dcc34d",
   "metadata": {},
   "source": [
    "### Tworzenie Konceptów dla pyCLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7190098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclad.data.concept import Concept\n",
    "\n",
    "train_concepts = []\n",
    "test_concepts = []\n",
    "\n",
    "for channel in msl_channels:\n",
    "    train_concept = Concept(name=channel, data=train_windows[channel])\n",
    "    train_concepts.append(train_concept)\n",
    "\n",
    "    test_concept = Concept(name=channel, data=test_windows[channel], labels=test_labels[channel])\n",
    "    test_concepts.append(test_concept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6daebd8",
   "metadata": {},
   "source": [
    "### Definicja datasetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5dbfac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclad.data.datasets.concepts_dataset import ConceptsDataset\n",
    "\n",
    "dataset = ConceptsDataset(\n",
    "    name=\"MSL_widows_dataset\",\n",
    "    train_concepts=train_concepts,\n",
    "    test_concepts=test_concepts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1bcefe",
   "metadata": {},
   "source": [
    "### Definicja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c029a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pyclad.models.model import Model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "class AEp(Model):\n",
    "    def __init__(self, input_dim, lr=1e-3, percentile=95, epochs=80):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.module = AE(self.input_dim).to(device)\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.percentile = percentile\n",
    "        self.threshold = None  # zostanie ustawiony po treningu\n",
    "\n",
    "    def fit(self, data: np.ndarray):\n",
    "        dataset = TensorDataset(torch.Tensor(data))\n",
    "        loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "        optimizer = torch.optim.Adam(self.module.parameters(), lr=self.lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        self.module.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0.0\n",
    "            for batch in loader:\n",
    "                x = batch[0].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                x_hat = self.module(x)\n",
    "                loss = loss_fn(x_hat, x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        self.module.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.Tensor(data).to(device)\n",
    "            x_hat = self.module(x)\n",
    "            rec_error = ((data - x_hat.cpu().numpy()) ** 2).mean(axis=1)\n",
    "            self.threshold = np.percentile(rec_error, self.percentile)\n",
    "\n",
    "    def predict(self, data: np.ndarray):\n",
    "        self.module.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.Tensor(data).to(device)\n",
    "            x_hat = self.module(x)\n",
    "            rec_error = ((data - x_hat.cpu().numpy()) ** 2).mean(axis=1)\n",
    "            binary_preds = (rec_error > self.threshold).astype(int)\n",
    "        return binary_preds, rec_error\n",
    "\n",
    "    def name(self):\n",
    "        return \"AEp\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ac17551",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AEp(input_dim=window_size, lr=1e-3, epochs=60, percentile=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209aea49",
   "metadata": {},
   "source": [
    "### Definicja strategii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa4f81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclad.strategies.baselines.cumulative import CumulativeStrategy\n",
    "from pyclad.strategies.baselines.naive import NaiveStrategy\n",
    "from pyclad.strategies.replay.replay import ReplayEnhancedStrategy\n",
    "from pyclad.strategies.baselines.mste import MSTE\n",
    "from pyclad.strategies.replay.buffers.adaptive_balanced import AdaptiveBalancedReplayBuffer\n",
    "\n",
    "from pyclad.strategies.replay.selection.random import RandomSelection\n",
    "\n",
    "replay_buffer = AdaptiveBalancedReplayBuffer(selection_method=RandomSelection(), max_size=1000)\n",
    "\n",
    "#strategy = NaiveStrategy(model)\n",
    "#strategy = CumulativeStrategy(model)\n",
    "strategy = ReplayEnhancedStrategy(model, replay_buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408b44c",
   "metadata": {},
   "source": [
    "### Callbacki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c28e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclad.callbacks.evaluation.concept_metric_evaluation import ConceptMetricCallback\n",
    "from pyclad.callbacks.evaluation.memory_usage import MemoryUsageCallback\n",
    "from pyclad.callbacks.evaluation.time_evaluation import  TimeEvaluationCallback\n",
    "\n",
    "from pyclad.metrics.base.roc_auc import RocAuc\n",
    "from pyclad.metrics.continual.average_continual import ContinualAverage\n",
    "from pyclad.metrics.continual.backward_transfer import BackwardTransfer\n",
    "from pyclad.metrics.continual.forward_transfer import ForwardTransfer\n",
    "\n",
    "from pyclad.callbacks.callback import Callback\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scores_matrix = {}\n",
    "        self.learned_concepts = []\n",
    "\n",
    "    def after_training(self, learned_concept, *args, **kwargs):\n",
    "        self.learned_concepts.append(learned_concept.name)\n",
    "        self.scores_matrix[learned_concept.name] = {}\n",
    "\n",
    "    def after_evaluation(self, *args, **kwargs):\n",
    "        y_true = kwargs.get(\"y_true\")\n",
    "        y_pred = kwargs.get(\"y_pred\")\n",
    "        concept = kwargs.get(\"evaluated_concept\")\n",
    "        if y_true is not None and y_pred is not None:\n",
    "            f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "            current_train = self.learned_concepts[-1]\n",
    "            self.scores_matrix[current_train][concept.name] = f1\n",
    "\n",
    "    def info(self):\n",
    "        return {\n",
    "            \"F1ScoreMatrix\": {\n",
    "                \"concepts_order\": self.learned_concepts,\n",
    "                \"matrix\": self.scores_matrix\n",
    "            }\n",
    "        }\n",
    "\n",
    "    \n",
    "class ClassificationReportCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reports_matrix = {}\n",
    "        self.learned_concepts = []\n",
    "\n",
    "    def after_training(self, learned_concept, *args, **kwargs):\n",
    "        self.learned_concepts.append(learned_concept.name)\n",
    "        self.reports_matrix[learned_concept.name] = {}\n",
    "\n",
    "    def after_evaluation(self, *args, **kwargs):\n",
    "        y_true = kwargs.get(\"y_true\")\n",
    "        y_pred = kwargs.get(\"y_pred\")\n",
    "        concept = kwargs.get(\"evaluated_concept\")\n",
    "\n",
    "        if y_true is not None and y_pred is not None:\n",
    "            report = classification_report(\n",
    "                y_true, \n",
    "                y_pred, \n",
    "                target_names=[\"Normal\", \"Anomaly\"], \n",
    "                output_dict=True,\n",
    "                zero_division=0\n",
    "            )\n",
    "            current_train = self.learned_concepts[-1]\n",
    "            self.reports_matrix[current_train][concept.name] = report\n",
    "\n",
    "    def info(self):\n",
    "        return {\n",
    "            \"ClassificationReportsMatrix \": {\n",
    "                \"concepts_order\": self.learned_concepts,\n",
    "                \"matrix\": self.reports_matrix\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ConceptMetricCallback(\n",
    "        base_metric=RocAuc(),\n",
    "        metrics=[ContinualAverage(), BackwardTransfer(), ForwardTransfer()]\n",
    "    ),\n",
    "    TimeEvaluationCallback(),\n",
    "    MemoryUsageCallback(),\n",
    "    F1ScoreCallback(),\n",
    "    ClassificationReportCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3fc59",
   "metadata": {},
   "source": [
    "### Uruchomienie scenariusza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab44ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyclad.output.json_writer import JsonOutputWriter\n",
    "from pyclad.scenarios.concept_aware import ConceptAwareScenario\n",
    "from pyclad.scenarios.concept_agnostic import ConceptAgnosticScenario\n",
    "import pathlib\n",
    "\n",
    "\n",
    "scenario = ConceptAwareScenario(\n",
    "    dataset=dataset,\n",
    "    strategy=strategy,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Uruchomienie eksperymentu\n",
    "scenario.run()\n",
    "\n",
    "output_writer = JsonOutputWriter(pathlib.Path(\"output-strategy1.json\"))\n",
    "output_writer.write([model, dataset, strategy, *callbacks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3706aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
